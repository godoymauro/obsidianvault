¬°Absolutamente! Has explorado las arquitecturas modernas (GraphQL, Serverless) y sabes que Node.js es r√°pido. Pero la verdadera prueba de fuego llega bajo **alta carga**. Una API exitosa debe ser capaz de manejar un aumento repentino de usuarios sin colapsar.

Esta clase te ense√±ar√° c√≥mo escalar Node.js m√°s all√° del l√≠mite de un solo proceso y c√≥mo optimizar el c√≥digo para un rendimiento m√°ximo.

Aqu√≠ tienes la nota para la clase anterior: **[[30 - Serverless]]**.

---

# 31 - Escalabilidad y performance

## üìö Introducci√≥n: Superando el L√≠mite del Hilo √önico

Recordemos el concepto clave de **[[03 - Node.js Runtime]]**: Node.js opera en un **√∫nico hilo** principal. Esto es genial para I/O (Input/Output) as√≠ncrono, pero si ese hilo se satura con tareas intensivas de CPU (c√°lculos pesados, compresi√≥n, criptograf√≠a s√≠ncrona), el rendimiento cae a cero.

La **Escalabilidad** en Node.js no se logra con un servidor m√°s grande (escalamiento vertical), sino con la duplicaci√≥n de procesos para distribuir la carga (**escalamiento horizontal**).

---

## üèó 1. Clustering: Escalado Horizontal en un Servidor

El m√≥dulo nativo **`cluster`** de Node.js permite que un √∫nico proceso maestro (el _master_) distribuya el tr√°fico de red a m√∫ltiples procesos hijos (los _workers_), cada uno ejecutando una copia de tu aplicaci√≥n. Esto aprovecha todos los n√∫cleos de la CPU de tu servidor.

### Principio de Funcionamiento

- **Master Process:** Escucha el puerto (ej: 3000) y maneja las conexiones entrantes.
    
- **Worker Processes:** Cada uno es un proceso de Node.js independiente y maneja las peticiones.
    
- **Balanceo de Carga:** El sistema operativo o el proceso maestro distribuyen las peticiones entre los _workers_ mediante una estrategia Round-Robin (uno a uno).
    

### Ejemplo con M√≥dulo `cluster` (Conceptual)

JavaScript

```
const cluster = require('node:cluster');
const os = require('node:os');
const express = require('express');

// Contamos los n√∫cleos de la CPU disponibles
const numCPUs = os.cpus().length; 

if (cluster.isMaster) {
    console.log(`[Master ${process.pid}] iniciado.`);

    // üí° Creamos un worker por cada n√∫cleo de CPU
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }

    // Manejar la muerte de un worker (esencial para la resiliencia)
    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} muri√≥. Iniciando uno nuevo...`);
        cluster.fork(); // ¬°Reemplazar el worker ca√≠do!
    });
} else {
    // üí° El c√≥digo que cada worker ejecuta (tu aplicaci√≥n Express)
    const app = express();
    app.get('/', (req, res) => {
        res.send(`Hola desde Worker ${process.pid}`);
    });

    app.listen(3000, () => {
        console.log(`[Worker ${process.pid}] escuchando en el puerto 3000.`);
    });
}
```

---

## üõ° 2. PM2: El Gestor de Procesos de Producci√≥n

En lugar de escribir y mantener la l√≥gica del m√≥dulo `cluster` manualmente, los desarrolladores de Node.js usan **PM2 (Process Manager 2)**.

**PM2** es una herramienta CLI que te permite:

1. **Modo Cluster:** Ejecutar tu aplicaci√≥n en modo cluster, aprovechando todos los n√∫cleos de CPU autom√°ticamente.
    
2. **Monitorizaci√≥n:** Mostrar el uso de CPU y RAM de cada proceso.
    
3. **Resiliencia:** Reiniciar autom√°ticamente tu aplicaci√≥n si falla o si un proceso worker muere.
    
4. **Zero Downtime Reload:** Recargar la aplicaci√≥n sin perder ninguna conexi√≥n (ideal para despliegues _rolling_).
    

### Comandos Clave de PM2

|Comando|Prop√≥sito|
|---|---|
|`npm install -g pm2`|Instalaci√≥n global.|
|`pm2 start app.js -i max`|Iniciar la aplicaci√≥n en modo cluster. `-i max` usa tantos procesos como n√∫cleos de CPU.|
|`pm2 list`|Muestra el estado de todos los procesos gestionados.|
|`pm2 monit`|Muestra el panel de monitoreo en tiempo real (CPU/RAM).|
|`pm2 reload all`|Reinicia todos los procesos sin inactividad.|

**PM2 es la herramienta de elecci√≥n para ejecutar Node.js directamente en VPS/IaaS (ej: DigitalOcean, AWS EC2).**

---

## ‚ö° 3. Optimizaci√≥n y Performance (C√≥digo)

El escalamiento horizontal (PM2, Docker) resuelve la saturaci√≥n de CPU, pero siempre debes asegurarte de que tu c√≥digo sea r√°pido.

### A. Almacenamiento en Cach√© (Caching)

El _caching_ es la herramienta m√°s efectiva para mejorar la _performance_ en el backend.

|Tipo de Cach√©|D√≥nde se Guarda|Cu√°ndo usar|Herramienta Node.js|
|---|---|---|---|
|**In-Memory Cache**|En la RAM del proceso de Node.js.|Datos peque√±os y muy consultados (ej: tokens de configuraci√≥n).|`node-cache`, `lru-cache`|
|**Distributed Cache**|En un servidor de cach√© dedicado (Redis o Memcached).|Datos que necesitan ser compartidos entre _todos_ los procesos (`cluster`) y microservicios.|`ioredis` (Cliente de Redis)|

**Regla de Oro:** Si una consulta a la BD es lenta y los datos cambian poco, **gu√°rdala en Redis** con un tiempo de expiraci√≥n corto (ej: 60 segundos).

### B. Workers Threads (Tareas Pesadas de CPU)

Para tareas **intensivas de CPU** (ej: miner√≠a de datos, compresi√≥n de im√°genes pesadas) que _no puedes_ evitar, Node.js ofrece el m√≥dulo **`worker_threads`**.

- Permite delegar la tarea de CPU a un **hilo separado** (un _worker_) que no es parte del Event Loop.
    
- El **hilo principal** permanece libre para atender peticiones, mientras el _worker_ procesa la tarea pesada.
    

JavaScript

```
const { Worker, isMainThread } = require('node:worker_threads');

if (isMainThread) {
    // El hilo principal sigue atendiendo peticiones
    // Delega la tarea pesada al worker
    const worker = new Worker('./worker.js'); 
    worker.on('message', (msg) => {
        console.log('Resultado del c√°lculo:', msg);
    });
} else {
    // worker.js: L√≥gica de c√°lculo intensivo
    parentPort.postMessage(resultado_del_calculo_pesado);
}
```

---

## ‚úÖ Buenas Pr√°cticas y Errores Comunes

|Categor√≠a|Buena Pr√°ctica|Error Com√∫n|
|---|---|---|
|**Balanceo**|Usar PM2 en modo **cluster** en VPS/IaaS, o el auto-escalado de contenedores (Kubernetes/ECS).|Ejecutar Node.js con `node app.js` en producci√≥n, usando solo un n√∫cleo de CPU.|
|**I/O**|Asegurar que **todas** las operaciones I/O (BD, archivos, red) sean **as√≠ncronas** y se basen en Promesas/`async/await`.|Usar funciones s√≠ncronas (`fs.readFileSync`, bucles muy largos) que bloquean el Event Loop y, por ende, a todos los _workers_ en el cluster.|
|**Cach√©**|Usar **Redis** (Distributed Cache) para datos compartidos y la invalidaci√≥n de cach√©.|Reimplementar soluciones de cach√© caseras en memoria que solo funcionan en un proceso y fallan en modo cluster.|
|**Mantenimiento**|Monitorear continuamente el uso de CPU y la latencia para identificar cuellos de botella y optimizar el c√≥digo.|Optimizar el c√≥digo _antes_ de identificar d√≥nde est√° el problema de rendimiento (optimizaci√≥n prematura).|

---

## üîë Resumen de Puntos Clave

- La **Escalabilidad** en Node.js se logra mediante el **escalamiento horizontal** (duplicando procesos), no vertical.
    
- El m√≥dulo nativo **`cluster`** permite aprovechar m√∫ltiples n√∫cleos de CPU.
    
- **PM2** es el gestor de procesos de producci√≥n que automatiza el modo cluster, la monitorizaci√≥n y la resiliencia (_auto-healing_).
    
- El **Caching (Redis)** es esencial para reducir la carga de la base de datos y la latencia.
    
- Para tareas **intensivas de CPU**, usa **Workers Threads** para no bloquear el Event Loop.
    

---

# üöÄ Nivel 6 Completado

¬°Felicidades! Has completado el **Nivel 6: Avanzado y arquitecturas modernas**. Ahora tienes las herramientas para construir APIs, microservicios y soluciones _serverless_ de alto rendimiento y escalabilidad.

Hemos cubierto la teor√≠a y las herramientas. Es hora de sintetizar todo en proyectos reales.

Entramos al **Nivel 7: Proyecto final**. Tu pr√≥xima clase ser√° la gu√≠a para construir una API RESTful completa desde cero: **[[32 - Proyecto guiado]]**.